{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "from shutil import copyfile\n",
    "from mmdet.apis import init_detector, inference_detector, show_result\n",
    "import glob\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "import torchvision\n",
    "import torch\n",
    "from mmdet.ops.nms import nms_cpu, nms\n",
    "from skimage.feature import match_template\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from psina_track_now_staff import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DATA_PATH = \"/home/mml6/IceChallenge/test/\"\n",
    "PREDICTIONS_PATH = \"Final_model/full_skolkovo_final_stage0_842.pkl\"\n",
    "PRED_THRESHOLD = 0.55\n",
    "IOU_NMS_THRESHOLD = 0.05\n",
    "MIN_BBOX_SQUARE = 100\n",
    "TRACKING_MIN_IOU = 0.001\n",
    "TRACKING_IOU_INTERPOLATE = 0.9\n",
    "TRACKING_MIN_CORRELATION = 0.5\n",
    "TRACKING_MAX_DISTANCE_PIXELS = 60\n",
    "BIG_CROP_PADDING = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREDICTIONS_PATH, 'rb') as fin:  \n",
    "    detector_predictions = filter_all_predictions(\n",
    "        pickle.load(fin),\n",
    "        PRED_THRESHOLD,\n",
    "        IOU_NMS_THRESHOLD,\n",
    "        MIN_BBOX_SQUARE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "\n",
    "for cur_img in glob.glob(IMAGES_DATA_PATH + \"**\", recursive=True):\n",
    "    if not \".jpg\" in cur_img:\n",
    "        continue\n",
    "    cur_img = '/'.join(cur_img.split('/')[-2:])\n",
    "    file_names.append(cur_img)\n",
    "\n",
    "file_names = np.array(file_names)\n",
    "video_seq = np.argsort(file_names)[::-1]\n",
    "selected_filenames = file_names[video_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_classes.txt') as f:\n",
    "    all_pos_classes = f.read().split()\n",
    "\n",
    "convert_class = lambda x: '.'.join(str(x).split('.')[:2])\n",
    "\n",
    "all_pos_classes = [convert_class(sign) for sign in all_pos_classes]\n",
    "\n",
    "valid_classes = sorted(\n",
    "    ['2.1',\n",
    "     '2.4',\n",
    "     '3.1',\n",
    "     '3.24',\n",
    "     '3.27',\n",
    "     '4.1',\n",
    "     '4.2',\n",
    "     '5.19',\n",
    "     '5.20',\n",
    "     '8.22'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_bboxes_iou(start_frame_bboxes, finish_frame_bboxes):\n",
    "    # Returns list of pairs (start_bbox, finish_bbox, start_bbox_index, finish_bbox_index)\n",
    "    # where each bbox is a pair (bbox, class_id)\n",
    "    \n",
    "    start_to_finish_iou = []\n",
    "    for i, start_bbox in enumerate(start_frame_bboxes):\n",
    "        for j, finish_bbox in enumerate(finish_frame_bboxes):\n",
    "            score = iou(start_bbox[0], finish_bbox[0])\n",
    "            if start_bbox[1] != finish_bbox[1]:\n",
    "                score = 0\n",
    "            \n",
    "            start_to_finish_iou.append((score, i, j))\n",
    "    \n",
    "    start_to_finish_iou.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    matched_pairs = []\n",
    "    used_start_bboxes = set()\n",
    "    used_finish_bboxes = set()\n",
    "    \n",
    "    for score, i, j in start_to_finish_iou:\n",
    "        if score < TRACKING_MIN_IOU:\n",
    "            break\n",
    "    \n",
    "        if i in used_start_bboxes or j in used_finish_bboxes:\n",
    "            continue\n",
    "        \n",
    "        start_bbox = start_frame_bboxes[i][:-1]\n",
    "        finish_bbox = finish_frame_bboxes[j][:-1]\n",
    "        matched_pairs.append((start_bbox, finish_bbox, i, j))\n",
    "        \n",
    "        used_start_bboxes.add(i)\n",
    "        used_finish_bboxes.add(j)\n",
    "\n",
    "    return matched_pairs\n",
    "\n",
    "def get_distance_between_bboxes(start_bbox, finish_bbox):\n",
    "    distance = (start_bbox[0] - finish_bbox[0]) ** 2 + (start_bbox[1] - finish_bbox[1]) ** 2\n",
    "    return distance ** (1 / 2.)\n",
    "\n",
    "def match_bboxes_template(start_frame, finish_frame):\n",
    "    # Returns list of pairs (start_bbox, finish_bbox, start_bbox_index, finish_bbox_index)\n",
    "    # where each bbox is a pair (bbox, class_id)\n",
    "    \n",
    "    start_frame_bboxes = start_frame[0]\n",
    "    finish_frame_bboxes = finish_frame[0]\n",
    "    \n",
    "    start_frame_img = start_frame[1]\n",
    "    finish_frame_img = finish_frame[1]\n",
    "    \n",
    "    start_to_finish_iou = []\n",
    "    for i, start_bbox in enumerate(start_frame_bboxes):\n",
    "        for j, finish_bbox in enumerate(finish_frame_bboxes):\n",
    "            if start_bbox[1] != finish_bbox[1]:\n",
    "                continue\n",
    "\n",
    "            distance = get_distance_between_bboxes(start_bbox[0], finish_bbox[0])\n",
    "            if distance > TRACKING_MAX_DISTANCE_PIXELS:\n",
    "                continue\n",
    "\n",
    "            start_crop = start_frame_img[\n",
    "                int(start_bbox[0][1]):int(start_bbox[0][1] + start_bbox[0][3]),\n",
    "                int(start_bbox[0][0]):int(start_bbox[0][0] + start_bbox[0][2])]\n",
    "\n",
    "            finish_crop = finish_frame_img[\n",
    "                int(finish_bbox[0][1]):int(finish_bbox[0][1] + finish_bbox[0][3]),\n",
    "                int(finish_bbox[0][0]):int(finish_bbox[0][0] + finish_bbox[0][2])]\n",
    "            \n",
    "            h = min(start_crop.shape[0], finish_crop.shape[0])\n",
    "            w = min(start_crop.shape[1], finish_crop.shape[1])\n",
    "            start_crop = cv2.resize(start_crop, (w, h))\n",
    "            finish_crop = cv2.resize(finish_crop, (w, h))\n",
    "\n",
    "            score = cv2.matchTemplate(start_crop, finish_crop, cv2.TM_CCOEFF_NORMED)[0][0]\n",
    "            \n",
    "            start_to_finish_iou.append((score, i, j))\n",
    "    \n",
    "    start_to_finish_iou.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    matched_pairs = []\n",
    "    used_start_bboxes = set()\n",
    "    used_finish_bboxes = set()\n",
    "    \n",
    "    for score, i, j in start_to_finish_iou:\n",
    "        if score < TRACKING_MIN_CORRELATION:\n",
    "            break\n",
    "    \n",
    "        if i in used_start_bboxes or j in used_finish_bboxes:\n",
    "            continue\n",
    "        \n",
    "        start_bbox = start_frame_bboxes[i][:-1]\n",
    "        finish_bbox = finish_frame_bboxes[j][:-1]\n",
    "        matched_pairs.append((start_bbox, finish_bbox, i, j))\n",
    "        \n",
    "        used_start_bboxes.add(i)\n",
    "        used_finish_bboxes.add(j)\n",
    "\n",
    "    return matched_pairs\n",
    "\n",
    "\n",
    "def match_bboxes(start_frame, finish_frame):\n",
    "    # Returns list of pairs (start_bbox, finish_bbox)\n",
    "    # where each bbox is a pair (bbox, class_id)\n",
    "    \n",
    "    matched_pairs = []\n",
    "    \n",
    "    matched_pairs_iou = match_bboxes_iou(start_frame[0], finish_frame[0])\n",
    "    start_bbox_indices_to_remove = set()\n",
    "    finish_bbox_indices_to_remove = set()\n",
    "    \n",
    "    for start_bbox, finish_bbox, start_bbox_index, finish_bbox_index in matched_pairs_iou:\n",
    "        start_bbox_indices_to_remove.add(start_bbox_index)\n",
    "        finish_bbox_indices_to_remove.add(finish_bbox_index)\n",
    "        \n",
    "        matched_pairs.append((start_bbox, finish_bbox))\n",
    "    \n",
    "    new_start_frame_bboxes = []\n",
    "    new_finish_frame_bboxes = []\n",
    "    \n",
    "    for i, bbox in enumerate(start_frame[0]):\n",
    "        if i not in start_bbox_indices_to_remove:\n",
    "            new_start_frame_bboxes.append(bbox)\n",
    "\n",
    "    for j, bbox in enumerate(finish_frame[0]):\n",
    "        if j not in finish_bbox_indices_to_remove:\n",
    "            new_finish_frame_bboxes.append(bbox)\n",
    "    \n",
    "    start_frame = [new_start_frame_bboxes, start_frame[1]]\n",
    "    finish_frame = [new_finish_frame_bboxes, finish_frame[1]]\n",
    "\n",
    "    matched_pairs_template = match_bboxes_template(start_frame, finish_frame)\n",
    "    \n",
    "    for start_bbox, finish_bbox, start_bbox_index, finish_bbox_index in matched_pairs_template:\n",
    "        matched_pairs.append((start_bbox, finish_bbox))\n",
    "\n",
    "    return matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tracking(sequence_tracking):\n",
    "    result = []\n",
    "\n",
    "    start_frame = sequence_tracking[0]\n",
    "    finish_frame = sequence_tracking[-1]\n",
    "    \n",
    "    start_frame_img = start_frame[1]\n",
    "    finish_frame_img = finish_frame[1]\n",
    "\n",
    "    interpolate_frames = sequence_tracking[1:-1]\n",
    "\n",
    "    matched_bboxes = match_bboxes(start_frame, finish_frame)\n",
    "\n",
    "    for frame_num, (_, image) in enumerate(interpolate_frames):\n",
    "        frame_bboxes = []\n",
    "        for start_bbox, finish_bbox in matched_bboxes:\n",
    "            class_id = start_bbox[1]\n",
    "            start_bbox = start_bbox[0]\n",
    "            finish_bbox = finish_bbox[0]\n",
    "            \n",
    "            start_bbox_size = [start_bbox[2], start_bbox[3]]\n",
    "            finish_bbox_size = [finish_bbox[2], finish_bbox[3]]\n",
    "            \n",
    "            bbox_diff = [\n",
    "                finish_bbox[0] - start_bbox[0],\n",
    "                finish_bbox[1] - start_bbox[1],\n",
    "                finish_bbox[2] - start_bbox[2],\n",
    "                finish_bbox[3] - start_bbox[3]]\n",
    "            \n",
    "            new_coarse_bbox = start_bbox[:]\n",
    "            for i in range(4):\n",
    "                new_coarse_bbox[i] += bbox_diff[i] / (len(interpolate_frames) + 1) * (frame_num + 1)\n",
    "                \n",
    "            \n",
    "            if iou(start_bbox, finish_bbox) > TRACKING_IOU_INTERPOLATE:\n",
    "                frame_bboxes.append((new_coarse_bbox, class_id, 1))\n",
    "                continue\n",
    "\n",
    "            start_bbox = hw_to_min_max(start_bbox)\n",
    "            finish_bbox = hw_to_min_max(finish_bbox)\n",
    "\n",
    "            bbox_find_area = [\n",
    "                min(start_bbox[0], finish_bbox[0]) - BIG_CROP_PADDING,\n",
    "                min(start_bbox[1], finish_bbox[1]) - BIG_CROP_PADDING,\n",
    "                max(start_bbox[2], finish_bbox[2]) + BIG_CROP_PADDING,\n",
    "                max(start_bbox[3], finish_bbox[3]) + BIG_CROP_PADDING\n",
    "            ]\n",
    "            \n",
    "            bbox_find_area = [\n",
    "                max(bbox_find_area[0], 0),\n",
    "                max(bbox_find_area[1], 0),\n",
    "                min(bbox_find_area[2], image.shape[1]),\n",
    "                min(bbox_find_area[3], image.shape[0]),\n",
    "            ]\n",
    "            \n",
    "            crop_proposals = []\n",
    "\n",
    "            start_crop = start_frame_img[\n",
    "                int(start_bbox[1]):int(start_bbox[3]),\n",
    "                int(start_bbox[0]):int(start_bbox[2])]\n",
    "#             crop_proposals.append((start_crop, start_bbox_size[0], start_bbox_size[1]))\n",
    "\n",
    "#             finish_crop = finish_frame_img[\n",
    "#                 int(finish_bbox[1]):int(finish_bbox[3]),\n",
    "#                 int(finish_bbox[0]):int(finish_bbox[2])]\n",
    "#             crop_proposals.append((finish_crop, finish_bbox_size[0], finish_bbox_size[1]))\n",
    "            \n",
    "            estimated_crop = cv2.resize(start_crop, (int(new_coarse_bbox[2]), int(new_coarse_bbox[3])))\n",
    "            crop_proposals.append((estimated_crop, estimated_crop.shape[1], estimated_crop.shape[0]))\n",
    "            \n",
    "            find_area_crop = image[\n",
    "                int(bbox_find_area[1]):int(bbox_find_area[3]),\n",
    "                int(bbox_find_area[0]):int(bbox_find_area[2])]\n",
    "            \n",
    "\n",
    "            crop_proposals_scores = []\n",
    "            for crop_proposal in crop_proposals:\n",
    "                score = cv2.matchTemplate(find_area_crop, crop_proposal[0], cv2.TM_CCOEFF_NORMED)\n",
    "                score_argmax = np.argmax(score)\n",
    "                \n",
    "                crop_proposals_scores.append((score_argmax, score, crop_proposal[1], crop_proposal[2]))\n",
    "            \n",
    "            \n",
    "            best_proposal = max(crop_proposals_scores, key=lambda x: x[0])\n",
    "            \n",
    "            match_result = np.unravel_index(best_proposal[0], best_proposal[1].shape)\n",
    "            new_y_min = float(match_result[0] + int(bbox_find_area[1])) # TODO test it!\n",
    "            new_x_min = float(match_result[1] + int(bbox_find_area[0]))\n",
    "            new_y_max = new_y_min + best_proposal[3]\n",
    "            new_x_max = new_x_min + best_proposal[2]\n",
    "            \n",
    "            new_bbox = [new_x_min, new_y_min, new_x_max, new_y_max]\n",
    "            new_bbox = min_max_to_hw(new_bbox)\n",
    "            \n",
    "            frame_bboxes.append((new_bbox, class_id, 1))\n",
    "        \n",
    "        result.append(frame_bboxes)\n",
    "\n",
    "    result.append(finish_frame[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 14999. Time: 63 s. ETA: 0 s"
     ]
    }
   ],
   "source": [
    "DETECTOR_FREQUENCY = 3\n",
    "\n",
    "dataset = ImageFilelist(IMAGES_DATA_PATH, selected_filenames)\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=12)\n",
    "loader = iter(loader)\n",
    "\n",
    "final_boxes = []\n",
    "start_time = time.time()\n",
    "\n",
    "current_sequence_tracking = []\n",
    "current_sequence_index = 0\n",
    "\n",
    "for ind in range(len(selected_filenames))[:]:\n",
    "    if ind == 0 or selected_filenames[ind].split('/')[0] != selected_filenames[ind-1].split('/')[0]:\n",
    "        # NEW SEQUENCE starts!!!\n",
    "        if len(current_sequence_tracking) > 0:\n",
    "            for boxes, _ in current_sequence_tracking[1:]:\n",
    "                final_boxes.append(boxes)\n",
    "        \n",
    "        current_sequence_tracking = []\n",
    "        current_sequence_index = 0\n",
    "\n",
    "    cur_img_gray = next(loader)[0][0].data.numpy()\n",
    "    #cur_img_gray = cv2.cvtColor(cur_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #continue\n",
    "    frame_predictions = detector_predictions[ind]\n",
    "    \n",
    "    frame_final_boxes = []    \n",
    "    if (not current_sequence_tracking) or ((len(current_sequence_tracking) + 1) % DETECTOR_FREQUENCY == 0):\n",
    "        frame_final_boxes = []\n",
    "        for prediction in frame_predictions:\n",
    "            bbox = prediction[:4]\n",
    "            class_id = int(prediction[4])\n",
    "            frame_final_boxes.append((bbox, class_id, 0))\n",
    "    \n",
    "    current_sequence_tracking.append((frame_final_boxes, cur_img_gray))\n",
    "    \n",
    "    if len(current_sequence_tracking) == DETECTOR_FREQUENCY:\n",
    "        if current_sequence_index == 0:\n",
    "            final_boxes.append(current_sequence_tracking[0][0])\n",
    "            current_sequence_index += 1\n",
    "        for boxes in run_tracking(current_sequence_tracking):\n",
    "            final_boxes.append(boxes)\n",
    "        \n",
    "        current_sequence_tracking = [current_sequence_tracking[-1]]\n",
    "\n",
    "    current_time = int(time.time() - start_time)\n",
    "    time_per_iter = (time.time() - start_time) / (ind + 1)\n",
    "    eta_time = int((len(selected_filenames) - ind) * time_per_iter)\n",
    "    print(\"\\rIndex: {}. Time: {} s. ETA: {} s\".format(ind, current_time, eta_time), end=\"\")\n",
    "\n",
    "if len(current_sequence_tracking) > 0:\n",
    "    for boxes, _ in current_sequence_tracking[1:]:\n",
    "        final_boxes.append(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tracking_check.tsv', 'w') as f:\n",
    "    f.write('\\t'.join(['frame', 'xtl', 'ytl', 'xbr', 'ybr', 'class']) + '\\n')\n",
    "    \n",
    "    for ind in range(len(selected_filenames)):\n",
    "        img_name = selected_filenames[ind]\n",
    "        img_name = img_name.replace('.jpg', '')\n",
    "        for bbox, class_id, _ in final_boxes[ind]:\n",
    "            class_id = int(class_id)\n",
    "            class_name = all_pos_classes[class_id]\n",
    "            if class_name not in valid_classes:\n",
    "                continue\n",
    "            bbox = hw_to_min_max(bbox)\n",
    "            bbox = list(map(str, bbox))\n",
    "            f.write('\\t'.join([img_name, *bbox, class_name]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score:\t787.791\n",
      "Total penalty:\t124.000\n",
      "Score 2.1:\t41.580\n",
      "Score 2.4:\t104.835\n",
      "Score 3.1:\t53.158\n",
      "Score 3.24:\t-5.280\n",
      "Score 3.27:\t56.303\n",
      "Score 4.1:\t53.973\n",
      "Score 4.2:\t55.698\n",
      "Score 5.19:\t255.439\n",
      "Score 5.20:\t140.381\n",
      "Score 8.22:\t31.703\n",
      "Penalty 2.1:\t12.000\n",
      "Penalty 2.4:\t26.000\n",
      "Penalty 3.1:\t6.000\n",
      "Penalty 3.24:\t36.000\n",
      "Penalty 3.27:\t6.000\n",
      "Penalty 4.1:\t10.000\n",
      "Penalty 4.2:\t4.000\n",
      "Penalty 5.19:\t24.000\n",
      "Penalty 5.20:\t0.000\n",
      "Penalty 8.22:\t0.000\n"
     ]
    }
   ],
   "source": [
    "!./score/target/release/icevision-score /media/mml6/HDD/Ice/annotations/final ~/IceChallenge/tracking_check.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCE SCORE\n",
    "\n",
    "# Total score:\t819.665\n",
    "# Total penalty:\t142.000\n",
    "# Score 2.1:\t43.085\n",
    "# Score 2.4:\t102.378\n",
    "# Score 3.1:\t57.288\n",
    "# Score 3.24:\t-2.041\n",
    "# Score 3.27:\t54.694\n",
    "# Score 4.1:\t58.172\n",
    "# Score 4.2:\t54.263\n",
    "# Score 5.19:\t283.166\n",
    "# Score 5.20:\t135.837\n",
    "# Score 8.22:\t32.821\n",
    "# Penalty 2.1:\t14.000\n",
    "# Penalty 2.4:\t28.000\n",
    "# Penalty 3.1:\t8.000\n",
    "# Penalty 3.24:\t36.000\n",
    "# Penalty 3.27:\t8.000\n",
    "# Penalty 4.1:\t10.000\n",
    "# Penalty 4.2:\t4.000\n",
    "# Penalty 5.19:\t24.000\n",
    "# Penalty 5.20:\t10.000\n",
    "# Penalty 8.22:\t0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "for cur_name, frame_final_predictions in zip(selected_filenames[:1000], final_boxes):\n",
    "    image = cv2.imread(os.path.join(IMAGES_DATA_PATH, cur_name))\n",
    "    for bbox, class_id, source in frame_final_predictions:\n",
    "        class_name = all_pos_classes[int(class_id)]\n",
    "        if class_name not in valid_classes:\n",
    "            continue\n",
    "        bbox = hw_to_min_max(bbox)\n",
    "        \n",
    "        if source == 0: # detector\n",
    "            cv2.rectangle(image, (int(bbox[0]), int(bbox[1])),\n",
    "                          (int(bbox[2]), int(bbox[3])),\n",
    "                          (0, 255, 0), 2)\n",
    "        elif source == 1: # tracking\n",
    "            cv2.rectangle(image, (int(bbox[0]), int(bbox[1])),\n",
    "                          (int(bbox[2]), int(bbox[3])), (0, 0, 255), 2)\n",
    "    \n",
    "        cv2.putText(image,\n",
    "                        class_name,# + ' ' + str(cur_prob)[:4],\n",
    "                        (int(bbox[0]), int(bbox[1])),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.5,\n",
    "                        (0, 255, 0),\n",
    "                        thickness=3,\n",
    "                        lineType=cv2.LINE_AA) \n",
    "    \n",
    "    cv2.imwrite('VisualTracking/' + cur_name.split('/')[1], image)\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "mmdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
